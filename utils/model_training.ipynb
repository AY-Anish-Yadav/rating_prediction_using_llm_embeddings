{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation (huge dataset)\n",
    "\n",
    "### Way1: \n",
    "1. Pandas with chunk size \n",
    "2. del unnecesary information, gc.collect() \n",
    "\n",
    "\n",
    "--->RuntimeError: [enforce fail at alloc_cpu.cpp:114] data. DefaultCPUAllocator: not enough memory: you tried to allocate 4374528000 bytes.\n",
    "\n",
    "### Way2\n",
    "\n",
    "1. Load and process the data in chunks.\n",
    "2. Embed the reviews using the UAE large v1 model.\n",
    "3. Save each chunk's embeddings and ratings to a temporary file.\n",
    "4. Combine all temporary files into a single NumPy array at the end.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedding Generation\n",
    "Looked into --->  MTEB Leaderboard (massive text embedding benchmark)\n",
    "### UAE - large-V1 (universal angie embeddings)\n",
    "1. Dimensions : 1024\n",
    "2. Time : took 1 hr for 3k records.\n",
    "3. Model Size : 1.25 GB (fp32)\n",
    "4. Context length (tokens) : 512\n",
    "5. price : open source\n",
    "\n",
    "### Voyage-large-2-instruct\n",
    "1. Dimensions : 1024\n",
    "2. Time : \n",
    "3. Model Size : \n",
    "4. Context length (tokens) : 16k\n",
    "5. price : $ 0.12 / 1 million tokens\n",
    "\n",
    "### text-embedding-3-small\n",
    "1. Dimensions : 1536\n",
    "2. Time : \n",
    "3. Model Size : \n",
    "4. Context length (tokens) : 512\n",
    "5. price : $ 0.02 / 1 million tokens\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Latency - Performance Trade - off :\n",
    "Delay between a user's action and the response from a system is known as an latency.\n",
    "2. Capturing Complexity of data - operational efficiency trade off:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to train your own embedding model?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load .npy file\n",
    "\n",
    "import numpy as np\n",
    "file=r\"D:\\projects_llm\\review_prediction_using_llm_embeddings\\temp_chunks\\ratings_embeddings.npy\"\n",
    "data=np.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(10000, 1025)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(type(data))\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1025,)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 4.        , -0.03100718, -0.00820842, ...,  0.01742723,\n",
       "        0.03722996,  0.02347247])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ML Techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split,GridSearchCV\n",
    "from sklearn.linear_model import LinearRegression,Ridge,Lasso\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_squared_error,r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = data[:,0]   # shape (10,000,)\n",
    "embeddings = data[:,1:] # shape (10,000,1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test=train_test_split(embeddings,ratings,test_size=0.25,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## 'Ridge Regression'\n",
    "# alpha: Regularization strength. Larger values specify stronger regularization. \n",
    "# The range of values here allows the model to try different levels of regularization to find the optimal one.\n",
    "\n",
    "## 'Lasso Regression'\n",
    "#alpha: Similar to Ridge Regression, alpha controls the regularization strength in Lasso Regression. \n",
    "# The values provided let the model explore different regularization strengths.\n",
    "\n",
    "## 'Random Forest Regressor'\n",
    "# n_estimators: The number of trees in the forest. Testing with different values (50, 100, 200) helps find the optimal number of trees.\n",
    "#max_depth: The maximum depth of each tree. Limiting the depth can prevent overfitting.\n",
    "#  None means nodes are expanded until all leaves are pure or contain fewer than the minimum samples.\n",
    "\n",
    "## 'SVM Regressor'\n",
    "# C: Regularization parameter. The strength of the regularization is inversely proportional to C. Smaller values specify stronger regularization.\n",
    "# epsilon: Specifies the epsilon-tube within which no penalty is associated in the training loss function.\n",
    "# kernel: Specifies the kernel type to be used in the algorithm. 'linear' uses a linear kernel, while 'rbf' uses a radial basis function kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# List of regressors and their parameter grids for hyperparameter tuning\n",
    "models = {\n",
    "    'Linear Regression': (LinearRegression(), {}),\n",
    "    'Ridge Regression': (Ridge(), {'alpha': [0.1, 1, 10]}),\n",
    "    'Lasso Regression': (Lasso(), {'alpha': [0.1, 1, 10]}),\n",
    "    'Random Forest Regressor': (RandomForestRegressor(), {'n_estimators': [100, 200], 'max_depth': [None, 10, 20]}),\n",
    "    'SVM Regressor': (SVR(), {'C': [0.1, 1, 10], 'epsilon': [0.01, 0.1, 0.2]}) # kernel : linear, RBF\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Components\n",
    "1. GridSearchCV:\n",
    "\n",
    "GridSearchCV is a function from scikit-learn used to perform an exhaustive search over specified parameter values for an estimator. It helps in finding the best combination of hyperparameters for a model.\n",
    "Parameters:\n",
    "\n",
    "a. model: The machine learning model/estimator to be optimized (e.g., LinearRegression(), Ridge(), SVR(), etc.).\n",
    "\n",
    "b. params: A dictionary where keys are the hyperparameter names and values are lists of values to try. For example, {'alpha': [0.1, 1, 10]} for Ridge Regression.\n",
    "\n",
    "c. cv=5: This sets up cross-validation with 5 folds. The data will be split into 5 parts, and the model will be trained and validated 5 times, each time using a different part of the data as the validation set and the remaining parts as the training set.\n",
    "\n",
    "d. scoring='neg_mean_squared_error': The scoring method to evaluate the predictions. neg_mean_squared_error is used because GridSearchCV expects a score to maximize. By using the negative MSE, it effectively minimizes the MSE.\n",
    "\n",
    "e. n_jobs=-1: This parameter allows the search to use all available CPU cores to parallelize the computation, speeding up the process.\n",
    "Fit the Grid Search:\n",
    "\n",
    "2. grid_search.fit(X_train, y_train): This line performs the grid search on the training data. It tries all combinations of parameters specified in params using cross-validation and evaluates them using the scoring method. The best combination of parameters is selected based on the cross-validation performance.\n",
    "Best Estimator:\n",
    "\n",
    "3. best_model = grid_search.best_estimator_: After fitting the grid search, grid_search.best_estimator_ contains the model with the best combination of hyperparameters found during the search.\n",
    "Store the Best Model:\n",
    "\n",
    "4. best_models[name] = best_model: This line stores the best model found for the current regressor in the best_models dictionary, using the name of the regressor as the key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression - Best Parameters: {}\n",
      "Linear Regression - Mean Squared Error: 0.609811512037517\n",
      "Linear Regression - R2 Score: 0.6989985696544256\n",
      "Ridge Regression - Best Parameters: {'alpha': 1}\n",
      "Ridge Regression - Mean Squared Error: 0.5744906312561676\n",
      "Ridge Regression - R2 Score: 0.7164328676733807\n",
      "Lasso Regression - Best Parameters: {'alpha': 0.1}\n",
      "Lasso Regression - Mean Squared Error: 2.0261129777777778\n",
      "Lasso Regression - R2 Score: -8.427573817559875e-05\n",
      "Random Forest Regressor - Best Parameters: {'max_depth': 20, 'n_estimators': 100}\n",
      "Random Forest Regressor - Mean Squared Error: 0.6321252902811235\n",
      "Random Forest Regressor - R2 Score: 0.6879845447710674\n",
      "SVM Regressor - Best Parameters: {'C': 1, 'epsilon': 0.2}\n",
      "SVM Regressor - Mean Squared Error: 0.5456886564468697\n",
      "SVM Regressor - R2 Score: 0.7306494500816224\n"
     ]
    }
   ],
   "source": [
    "best_models = {}\n",
    "from joblib import dump\n",
    "# Train, tune, and evaluate each model\n",
    "for name, (model, params) in models.items():\n",
    "    grid_search = GridSearchCV(model, params, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "    grid_search.fit(x_train, y_train)\n",
    "    \n",
    "    best_model = grid_search.best_estimator_\n",
    "    best_models[name] = best_model\n",
    "    \n",
    "    y_pred = best_model.predict(x_test)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    \n",
    "    print(f'{name} - Best Parameters: {grid_search.best_params_}')\n",
    "    print(f'{name} - Mean Squared Error: {mse}')\n",
    "    print(f'{name} - R2 Score: {r2}')\n",
    "\n",
    "# Save the best model for each regressor\n",
    "for name, model in best_models.items():\n",
    "    dump(model, f'{name.replace(\" \", \"_\").lower()}_best_model.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
